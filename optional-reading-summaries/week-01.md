## n.d. — Dennett, D. C. (n.d.). A Précis of The Intentional Stance. *Philosophical Review.*

**Full Citation:** Dennett, D. C. (Précis). A Précis of *The Intentional Stance*.

**Topic Tags:** intentional stance, Searle critique, heuristic overlay, consensus in philosophy of mind

### Core Question / Problem
Why is the intentional stance defensible as a pragmatic, heuristic strategy given critiques (e.g., Searle's Chinese Room) that demand metaphysical grounding?

### Conceptual or Computational Framework
Dennett argues the stance is a "heuristic overlay" that captures a community of practices; disagreements often reflect overstatements rather than deep problems. The defense emphasizes explanatory power and empirical adequacy over metaphysical commitments. 

### Methods Overview
Essay‑length précis with commentary on contemporary debates (Sellars, Quine, Searle, Fodor) and notes on the consensus shifting toward a moderate, pragmatic view.

### Key Findings
- Responds to Searle: even if biochemistry produces intentionality, that doesn't resolve the epistemic/practical reasons we adopt the stance.   
- Philosophers are converging on seeing intentional attribution as a useful heuristic rather than a metaphysical claim. 

### Interpretation & Significance
The Précis helps students situate Dennett historically and shows why the Intentional Stance remains influential: it provides an operational toolkit for prediction and explanation across domains (AI, economics, psychology). 

### Teaching Hooks
- Pair the précis with the 1971 article and Searle’s Chinese Room thought experiment for an in‑class debate.

---

## 1971 — Dennett, D. C. (1971). Intentional Systems. *The Journal of Philosophy.*

**Full Citation:** Dennett, D. C. (1971). Intentional Systems. *The Journal of Philosophy* / collected essays.

**Topic Tags:** intentional stance, design stance, physical stance, intentional systems, rationality, heuristics

### Core Question / Problem
What does it mean to treat systems (organisms, machines) as having beliefs and desires — and how useful is that strategy for explanation and prediction?

### Conceptual or Computational Framework
Dennett defines an Intentional System as any system whose behavior can be predicted by ascribing beliefs, desires, and rationality. He contrasts three explanatory stances: Physical (laws), Design (function), and Intentional (attributing mental states). The intentional stance is a heuristically powerful, stance‑level algorithm for prediction. Map to Marr: computational level = predicting behavior; algorithmic level = adopting a stance (rule set for ascription); implementational level = physical/biological substrate (irrelevant to stance validity).

### Methods Overview
Philosophical analysis and illustration (AI/chess, game theory, Skinner’s behaviorism counterexamples). Dennett uses thought experiments and cross‑disciplinary examples (economics, AI) to show how intentional descriptions simplify complex design problems.

### Key Findings
- Intentional characterization is useful even for non‑biological systems (chess programs) and yields genuine predictive power without needing metaphysical claims about consciousness.
- Treating agents as rational approximators explains why economics and game theory succeed even if psychology must explain that rationality.
- The concept is "uncluttered" — it avoids metaphysical commitments and focuses on predictive/organizational utility.

### Interpretation & Significance
Dennett offers a pragmatic account: intentionality as a tool, not a metaphysical property. For social cognition, this legitimizes mental‑state attribution as an adaptive predictive strategy (aligns with course’s Intentional Stance entry). It also explains cross‑disciplinary borrowings (AI, economics) where intentional terms function as useful heuristics. 

### Computational‑Social‑Cognitive‑Scientist Hat
- Lewin: Intentional ascription is a representational heuristic within the life‑space affecting behavior prediction.
- Marr: Intentional stance sits at an algorithmic/heuristic level for social prediction.

### Teaching Hooks
- Use chess programs and thermostats to show when intentional attributions help/hinder prediction.  
- Contrast with Searle’s Chinese Room (see the Précis commentary) to spark debate about "real" intentionality.

### Pedagogical Lens
- Prereqs: Familiarity with basic philosophy of mind and attribution theory.
- Misconceptions: That ascribing beliefs requires consciousness.

### Connections
- Directly connects to Intentional Stance, Design Stance, Mentalizing, and Generative Models in the glossary. 

### Key Quotes or Phrases
- "The concept of an Intentional system is a relatively uncluttered and unmetaphysical notion."

### Concept Graph
- System complexity → choice of stance (physical/design/intentional) → prediction accuracy.

---

## 2010 — Epley, N., & Waytz, A. (2010). Mind Perception. *In S. T. Fiske (Ed.), Handbook of Social Psychology (5th ed.).*

**Full Citation:** Epley, N., & Waytz, A. (2010). Mind Perception. In *Society & Animals* / Social Cognition chapter (selected pages).

**Topic Tags:** mentalizing, mind perception, animacy, agency, experience

### Core Question / Problem
How do people perceive "minds" in others (human and non‑human), what dimensions organize those perceptions, and how do those perceptions influence social judgment and behavior?

### Conceptual or Computational Framework
Epley & Waytz frame mind perception as a graded, two‑dimensional attributional space (Experience vs Agency) that functions as an early *preattributional* step in social cognition: first, perceivers ask “Does it have a mind?” then “What state is it in?”. This sits naturally at Marr’s Algorithmic level (representations: 2‑D mind space; operations: cues→attribution) and connects to the Computational level via the goal of enabling prediction and coordination in social environments.

### Methods Overview
This is a conceptual synthesis and review integrating laboratory experiments (e.g., cue manipulations that trigger animacy), developmental studies (infant sensitivity to teleology/goal-directed motion), cross‑cultural evidence, and moral judgment paradigms (e.g., attributions of responsibility and dehumanization). Core manipulations reviewed include motion cues, agency cues, moral contexts, and social distance (ingroup/outgroup).

### Key Findings
- Mind perception is structured primarily along two separable dimensions: **Experience** (capacity to feel) and **Agency** (capacity to plan/act). These vary independently across targets (e.g., pets = high experience/low agency; gods = high agency/low experience). 
- Perceivers use perceptual and contextual cues (animacy, goal‑directed motion, social closeness) to infer mind status; these inferences serve predictive and moral functions (assigning blame/praise, granting moral worth). 
- Mind perception is modulated by social distance and culture: ingroup members are attributed richer mental capacities than distant outgroups, and interdependent cultures show greater habitual perspective taking. 
- Errors and biases occur: people over‑attribute intentionality (leading to blame) and under‑attribute experience to dehumanized groups; activation of mind perception is effortful and context‑dependent. 

### Interpretation & Significance
Epley & Waytz show that mind perception is not a binary cognitive act but a graded representational mapping that scaffolds later causal attributions and moral evaluations. Mechanistically, the two‑dimensional representation compresses complex mental states into actionable summaries for social coordination and prediction. In course framing, this work demonstrates how Lewin’s B = f(P,E,R) benefits from an explicit representation (R) for other minds and connects to the Predictive Mind: attributing mental states improves prediction and coordination.

### Computational‑Social‑Cognitive‑Scientist Hat
- Lewin: Mind perception supplies the “R” (representation) that mediates how person and environment produce behavior.
- Marr: Algorithmic level — the two‑dimensional mind map is the representation; computational level — goal is accurate social prediction & moral evaluation.
- Brunswik: Emphasizes cue validity and ecological sampling — which cues reliably indicate agency or experience across contexts.

### Teaching Hooks
- Show Heider & Simmel animation and ask students to rate Experience/Agency for shapes.
- Moral vignette: vary perceived agency (intentional vs accidental) to generate graded blame judgments.
- Cultural comparison activity: short negotiation task with manipulated interdependence prompts.

### Pedagogical Lens
- Pre‑requisites: basic attribution theory; Heider & Simmel; dimensions (warmth/competence) analogy.
- Common misconceptions: mind perception = ToM; actually it’s a perceptual/preattributional step.
- Exam prompt: "Explain how Experience and Agency differ and why each matters for moral judgment. Provide experimental evidence."

### Connections
Links to animacy, intentional stance, Theory of Mind, predictive processing, and dehumanization literature. Useful precursor reading before Wang et al. (2025).

### Key Quotes or Phrases
- "Mind perception is a pre‑attributional process: first do we see a mind, then what is that mind like?" 
- "Perceiving mindful agency is tied to causal responsibility; perceiving experience is tied to moral worth." 

### Concept Graph
- Perceptual cues → (animacy detection) → Mind presence estimate → Map onto (Agency, Experience) → Guides prediction & moral judgment.

---

## 2007 — Gray, H. M., Gray, K., & Wegner, D. M. (2007). Dimensions of Mind Perception. *Science.*

**Full Citation:** Gray, H. M., Gray, K., & Wegner, D. M. (2007). Dimensions of Mind Perception. *Science*, 315, 619–619.

**Topic Tags:** mind perception, agency, experience, dimensionality reduction, social evaluation

### Core Question / Problem
Do people represent minds in others along meaningful dimensions, and if so, what are those dimensions and their psychological consequences?

### Conceptual or Computational Framework
Gray et al. provide experimental evidence for a low-dimensional representation of minds (primarily Agency and Experience). At Marr’s levels: computational goal = compress a high-dimensional space of possible mental features into tractable dimensions for fast inference; algorithmic = two-dimensional mapping; implementational = patterns of attribution consistent across participants and correlations with moral judgments.

### Methods Overview
Multiple experiments: participants rated a variety of targets (humans, animals, gods, robots) on trait adjectives; principal components / factor analyses revealed two stable dimensions. Follow-up behavioral measures connect dimensions to moral judgments and perceived responsibility.

### Key Findings
- A two-factor structure (Experience, Agency) captures most variance in mind attributions.
- These dimensions predict distinct moral consequences: Experience predicts moral rights (do not harm), Agency predicts moral responsibility (blame, praise).

### Interpretation & Significance
A compact representational account explains diverse phenomena — anthropomorphism, dehumanization, moral judgments — by showing that a small set of latent dimensions governs social inference. This aligns with computational cognitive science’s emphasis on compressed representations for efficient prediction.

### Teaching Hooks
- Quick rating exercise: give students target list (baby, dog, robot, corpse) and ask them to place each on two axes.
- Explain PCA as a method for discovering dimensions.

### Pedagogical Lens
- Difficulty: 2/5
- Pre-reqs: basic stats (factor/PCA), ToM
- Misconception: dimensions are mutually exclusive; many targets score on both.

### Connections
- Strongly connected to Epley & Waytz, Waytz et al., and course glossary terms like agency/experience and moral typecasting.

### Key Quotes or Phrases
- "Mind perception is organized along dimensions of experience and agency."

### Concept Graph
- Target features → (map to) Agency/Experience → (drive) moral judgments.

---

## 1944 — Heider, F., & Simmel, M. (1944). An Experimental Study of Apparent Behavior. *Journal of Psychology.*

**Full Citation:** Heider, F., & Simmel, M. (1944). *An Experimental Study of Apparent Behavior.* Journal of Psychology.

**Topic Tags:** Attribution theory, Animacy, Intentional stance

### Core Question / Problem
How do simple motion cues (shapes moving on a screen) provoke attributions of intentional action, social motives, and personality — i.e., when do observers treat abstract motion as “agents”?

### Conceptual or Computational Framework
Heider & Simmel operationalize the perceiver as a naïve scientist who infers internal states (beliefs, desires, intentions) from minimal perceptual input. At Marr’s levels: computationally, the problem is “infer causes (agents, goals) from motion”; algorithmically, it is mapping kinematic patterns to intentional explanations; implementational details are left unspecified.

### Methods Overview
Participants watched a short silent film showing geometric shapes (triangles, circle, rectangle) moving in a simple 2-D arena. They were asked to describe what they saw in their own words. The key manipulation is purely perceptual: only motion and spatial relations vary.

### Key Findings
- Nearly all observers provided narrativized, agentic descriptions (e.g., “the big triangle chased the little one to punish it”), attributing goals, beliefs, and social roles to geometric shapes.
- Motion patterns (self-propulsion, contingent interaction, approach/avoidance, goal-directed trajectories) reliably trigger attributions of animacy and intentionality.
- Observers spontaneously create causal and moral narratives from minimal cues.

### Interpretation & Significance
Heider & Simmel provide a clear demonstration that perception alone can trigger high-level social inferences. The study shows that agency detection and mentalizing are fast, automatic, and driven by diagnostic motion signatures — a foundational result for research on animacy perception, mentalizing, and the intentional stance.

### Computational‑Social‑Cognitive‑Scientist Hat
- Lewin: B = f(P, E, R) — This shows how perceptual input P (motion) combined with prior Representations (R: schemas about agents) shapes behavior (attribution).
- Marr: Computational goal = infer hidden agents/goals; algorithmic = mapping motion features → intentional explanation; implementational = unspecified.
- Brunswik: Emphasizes ecological validity — motion cues are probabilistic signals of agency and the perceiver uses ecological sampling (available cues) to infer hidden causes.

### Teaching Hooks
- Show short clips from the original animation and ask students to write 2‑sentence narratives; compare across students.
- Live demo: Two dots move contingently vs. randomly; ask students “Which is alive?” and discuss why.

### Pedagogical Lens
- Pre‑requisites: basic idea of attribution and agency
- Common misconceptions: “Attribution requires rich cues” — Heider & Simmel show minimal cues suffice.
- Discussion prompt: What motion features would an algorithm use to decide “agent” vs “object”?

### Connections
- Links to animacy literature, biological motion (Johansson), and predictive‑processing accounts where small prediction errors about self‑propelled motion trigger agent hypotheses.

### Key Quotes or Phrases
- “Observers impose intentions and social roles on moving shapes.”  
- “Motion alone is sufficient to elicit richly structured social narratives.”

### Concept Graph
- Motion cues (self‑propulsion, contingency) → Animacy detection → Intentional stance → Mentalizing (goal/trait attributions)

---

## 1973 — Johansson, G. (1973). Visual Perception of Biological Motion and a Model for Its Analysis. *Perception & Psychophysics.*

**Full Citation:** Johansson, G. (1973). Visual Perception of Biological Motion and a Model for Its Analysis. *Perception & Psychophysics*, 14(2), 201–211.  

**Topic Tags:** Biological Motion; Animacy; Perceptual Grouping; Vector Analysis; Representation

### Core Question / Problem
How can observers recover rich information about biological actions (walking, running, dancing) from extremely sparse motion signals (point-light displays), and what computational principles might the visual system use to perform this inference?

### Conceptual or Computational Framework
Johansson proposes a **visual vector-analysis** approach: the proximal motion field is decomposed into common (global/translatory) and residual (pendular/rotational) motion components; grouping is achieved by pooling elements that share equal motion components. Framed by Marr’s levels: (a) Computational — infer distal biological motion type from proximal motion; (b) Algorithmic — hierarchical vector decomposition and grouping; (c) Implementational — hypothesized low-level perceptual machinery (unspecified neural substrate).

### Methods Overview
Experimental manipulations use point-light displays (typically 10–12 joint markers, variants with as few as 5), transformations that add/subtract global motion components, and controlled perturbations (rotations, phase shifts). Measures include rapid recognition, verbal descriptions, and forced-choice identification by naive observers viewing brief sequences.

### Key Findings
- Sparse point-light configurations robustly evoke vivid impressions of human actions; observers identify actions quickly and reliably.  
- Recognition remains rapid (<1 s) and resilient to large manipulations of common motion components, supporting an automatic decomposition process.  
- Vector-analysis principles (subtract common components to reveal residual pendular/rotational motion) explain perception of articulated limbs and gait.  
- Even very minimal displays (≈5 points) can suffice for reliable identification — kinematic relations (phase, pendular timing) carry the bulk of information.

### Interpretation & Significance
This paper established point-light biological motion as a foundational paradigm for social perception: motion alone carries rich cues to animacy, action type, and identity. Johansson’s geometric-kinematic account emphasizes lawful, proximal computations that recover distal structure, seeding decades of work on biological motion, animacy detection, and neural substrates (e.g., STS/pSTS).

### Computational-Social-Cognitive-Scientist Hat
- **Lewin:** motion is ecologically valuable — life-space dynamics provide critical social information.
- **Marr:** applauds the explicit algorithmic account (vector decomposition) but asks for formal representation and error metrics.
- **Brunswik:** highlights which kinematic relations are reliable cues (phase, constant lengths) and how the system might weight them.

### Teaching Hooks
- Show classic point-light walker clips and ask students to name the action before revealing the source. 
- Demonstration: remove global translation and show residual pendular motion to illustrate decomposition.

### Pedagogical Lens
- **Conceptual difficulty:** 2–3/5.  
- **Pre-reqs:** basic motion perception, Gestalt grouping (common fate), central-projection geometry.  
- **Exam prompt:** Explain how subtracting a common motion component reveals pendular residuals that support limb perception.

### Connections
Links to Animacy, Mentalizing (motion cues can trigger social attributions), and Predictive Mind (motion provides input for forecasting actions). 

### Key Quotes or Phrases
- “10–12 such elements in adequate motion combinations evoke a compelling impression of human walking.” 

### Concept Graph
Joint-motion phase relations → perceived gait; Common-component subtraction → residual limb oscillation → animacy inference.

### Relevant Terms
**Existing Terms Used:** Biological Motion; Animacy; Perceptual Grouping; Representation. 

---

## 2020 — Perez-Osorio, J., & Wykowska, A. (2020). Adopting the Intentional Stance Toward Natural and Artificial Agents. *Philosophical Psychology.*

**Full Citation:** Perez-Osorio, J. & Wykowska, A. (2020). Adopting the Intentional Stance Toward Natural and Artificial Agents. *Philosophical Psychology* (accepted manuscript Feb 2019).

**Topic Tags:** intentional stance, human-robot interaction, social attunement, stance-taking

### Core Question / Problem
When and why do humans adopt the intentional stance — treating a system as if it has beliefs and desires — and what does it imply for interactions with artificial agents (robots, AI)?

### Conceptual or Computational Framework
The paper treats the intentional stance as an efficient predictive strategy: when the design or behavior of an agent makes intentional inference pay off, humans adopt it. Marr’s computational level: achieve accurate prediction in social settings; algorithmic: stance selection (physical/design/intentional) based on cue reliability, task demands, and cultural norms; implementational implications for robot design (appearance, contingency) to promote social attunement.

### Methods Overview
A literature review integrating philosophy (Dennett), developmental findings on stance emergence, cross-cultural variability, and HRI studies showing how robot appearance and contingency modulate adoption of the intentional stance.

### Key Findings
- Intentional stance is a fast, pragmatic strategy rather than a metaphysical claim about true intentionality.
- Robot features that increase contingency, goal-directed motion, and communicative signals increase adoption of the stance and social attunement.
- Cultural norms influence how readily people anthropomorphize and the norms governing acceptable stance adoption.

### Interpretation & Significance
For computational social cognition, the paper clarifies that adopting an intentional stance is an inference policy: agents (including designers) can manipulate cues to make mentalistic predictions more reliable, shaping social interaction. It connects philosophical theory (Dennett) directly to empirical HRI evidence.

### Teaching Hooks
- Show short clips of robots with varying human-likeness; ask students which stance they'd use and why.
- Mini design challenge: propose 3 features that would increase intentional stance adoption for a service robot.

### Pedagogical Lens
- Difficulty: 3/5
- Pre-reqs: intentional stance, agency, predictive models
- Misconception: adopting stance = believing the machine is conscious.

### Connections
- Links to Epley & Waytz, Gray et al., and course glossary entries on the intentional stance and animacy.

### Key Quotes or Phrases
- "Adopting the intentional stance is a pragmatic predictive strategy that facilitates social attunement."

### Concept Graph
- Robot cues (contingency, appearance) → (increase) Intentional stance adoption → (increase) Social attunement/perceived mind.
## 2013 — Sievers, B., Polansky, L., Casey, M., & Wheatley, T. (2013). Music and movement share a dynamic structure that supports universal expressions of emotion. *PNAS.*

**Full Citation:** Sievers, B., Polansky, L., Casey, M., & Wheatley, T. (2013). *Music and movement share a dynamic structure that supports universal expressions of emotion.* Proceedings of the National Academy of Sciences.

**Topic Tags:** cross-modal dynamics, emotion, biological motion, representation

### Core Question / Problem
Do music and movement share a **common dynamic code** for emotion that generalizes across cultures? 

### Conceptual or Computational Framework
A cross-modal representational geometry: emotional meaning maps onto low-level dynamical features (tempo, jitter, amplitude) that receivers use for inference. **Computationally**, efficient affect communication; **algorithmically**, reduce high-dimensional dynamics to a low-dimensional emotion space. 

### Methods Overview
Participants sculpted music and animations with sliders to express emotions; a remote Kreung sample replicated mappings. Analyses: clustering in parameter space, Monte-Carlo tests, and ANOVA across settings. 

### Key Findings
- Music and movement converge on similar feature configurations for the same emotions (cross-modal clustering).  
- Broad cross-cultural similarity supports a shared code; dynamical features reliably predict perceived emotion. 

### Interpretation & Significance
Identifies concrete features for models of affect perception and generative social signaling—useful input channels to students’ predictive-processing intuitions about how we read others’ states. 

### Computational-Social-Cognitive-Scientist Hat
- **Brunswik:** Cue reliability across cultures → ecological validity.  
- **Marr:** Precisely specifies the *algorithmic* features likely read out by receivers. 

### Key Quotes or Phrases
- "Auditory and visual cortex represent emotional music and movement in comparable terms."
- "Sensory brain regions represent conjunctions of task‑relevant features, reducing the need for downstream inferential processing."

### Concept Graph
- Stimulus features (speed, jitter, consonance, size, up/down) → sensory representational geometry (because distance in feature space maps to neural pattern distance).
- Sensory representational geometry → emotion judgments (because configural combinations align with perceived emotions).
- pSTG (supramodal) ↔ sensory cortices (facilitates crossmodal comparison and integration).
  - **Representation:** The format or structure by which the brain encodes information about the world. **Related Concepts:** cross-modal dynamics, neural geometry.
  - **Cross-modal dynamics:** How information from different sensory modalities (vision, audition) interacts and is integrated in the brain. **Related Concepts:** representation, supramodal representation.
  - **Mentalizing:** The process of reasoning about others' mental states; emotion perception from music and movement supports social inferences. **Related Concepts:** theory of mind, social cognition.
  - **Marr's levels:** David Marr's framework for analyzing cognitive systems at computational, algorithmic, and implementational levels. **Related Concepts:** computational modeling, levels of analysis.
  - **Animacy:** The perception of whether something is alive or capable of self-motion; related to detecting goal-directed movement. **Related Concepts:** biological motion, agency perception.

---

## 2019 — Sievers, B., Lee, C., Haslett, W., & Wheatley, T. (2019). A multi-sensory code for emotional arousal. *Proceedings of the Royal Society B.*

**Full Citation:** Sievers, B., Lee, C., Haslett, W., & Wheatley, T. (2019). *A multi-sensory code for emotional arousal.* Proceedings of the Royal Society B.

**Topic Tags:** emotional arousal, spectral centroid, multi-sensory code, predictive models

### Core Question / Problem
Is there a single low-level statistic that robustly signals **arousal** across modalities? Tests spectral centroid as a supramodal cue used by senders and decoded by receivers. 

### Conceptual or Computational Framework
**Computationally**, arousal estimation is a low-dimensional decoding problem; **algorithmically**, extracting the central tendency of frequency content (spectral centroid) supports cross-modal arousal judgments (sound, speech, movement, visual form). 

### Methods Overview
Regression and Bayesian classifiers relate spectral-centroid-like features to arousal ratings across datasets (e.g., emotional speech), testing generalization and discrimination (AUCs). 

### Key Findings
- Higher spectral centroid → higher perceived arousal across modalities.  
- Classifiers using centroid features discriminate arousal strongly and generalize across datasets. 

### Interpretation & Significance
Provides an implementable feature for computational models of affect perception and cross-channel social communication—ideal for students’ projects linking signal processing to social inference. 

### Computational-Social-Cognitive-Scientist Hat
- **Lewin:** Adds a measurable R mediating P/E → behavior.  
- **Marr:** Clear *algorithmic* feature with plausible *implementational* correlates (neural coding of spectral statistics). 

---

## 2021 — Sievers, B., et al. (2021). Visual and auditory brain areas share a representational structure that supports emotion perception. *Current Biology.*

**Full Citation:** Beau Sievers, Carolyn Parkinson, Peter J. Kohler, James M. Hughes, Sergey V. Fogelson, Thalia Wheatley (2021). Visual and auditory brain areas share a representational structure that supports emotion perception. *Current Biology.*

**Topic Tags:** mentalizing, representation, cross-modal dynamics, emotion perception, representational similarity analysis (RSA), supramodal representation

### Core Question / Problem
Why do music and movement so reliably convey the same emotions? The paper asks whether auditory and visual sensory regions use a shared representational geometry that puts music and movement into directly comparable neural terms — and whether that shared geometry encodes simple stimulus features, task‑relevant feature conjunctions tied to emotion judgments, or both.

### Conceptual or Computational Framework
Sievers et al. use the language of **representational geometry** (Kriegeskorte-style RSA) to test two nested hypotheses: (H1) modality‑specific auditory and visual regions share the same representational geometry (separate regions, shared representations) and (H2) one or more supramodal regions (e.g., posterior superior temporal cortex) instantiate a unified geometry for both modalities. At Marr's levels: the **computational** level asks what problem is solved (detect/recover emotion across modalities); the **algorithmic** level is the RSA-measurable geometry and the feature/judgment RDMs (representations mapping stimuli → internal distances); the **implementational** level is the neural substrate (lingual gyrus, superior temporal gyrus, pSTG/pSTS and distributed occipito‑temporal areas).

### Methods Overview
Stimuli: short piano melodies and animations of a bouncing ball generated from the same 5 feature parameters (speed, irregularity/jitter, consonance/spikiness, ratio big/small movements, ratio up/down). Prototype emotions (angry, happy, peaceful, sad, scared), linear mixes (25–75%), and three neutral points produced 76 stimulus classes; 20 probabilistic exemplars per class.

Behavioral: N = 79 participants rated emotion content (5 sliders). fMRI: subset N = 20 completed 18 runs (1,368 stimulus impressions total), event‑related design with optimized timings; participants had prior familiarity from the behavioral task.

Analysis: searchlight RSA compared neural representational dissimilarity matrices (neural RDMs) to a model built from ten predictor RDMs (five stimulus‑feature RDMs; five emotion‑judgment RDMs). Multiple regression RSA produced R²_adj, b‑weights, and Spearman correlations; intermodal RSA and a model‑free region similarity permutation test provided converging evidence.

### Key Findings
- Behavioral ratings clustered tightly around stimulus classes, validating the stimulus design.
- A single model (feature + emotion‑judgment RDMs) explained patterns in visual cortex during animation and auditory cortex during music, supporting H1 (shared representational geometry across separate sensory regions).
- Peaks: left medial lingual gyrus (animation) and right anterior superior temporal gyrus (music) (mean R²_adj ≈ 0.15). Model‑free tests showed these region pairs more similar than expected by chance (r = 0.68, p < .001).
- pSTG showed overlapping model fits across participants, supporting H2 (a supramodal hub) in a subset of participants.
- Both stimulus‑feature predictors and emotion‑judgment predictors were significant contributors, supporting coexistence of the **simple features** (A1) and **environmental conjunctions** (A2) hypotheses.
- Exploratory intermodal RSA revealed visual areas (including left lingual gyrus) that represented stimuli presented in the non‑preferred modality (auditory), although modality‑specific activity remained dominant.

### Interpretation & Significance
The brain appears to construct a cross‑modal representational geometry that maps changes in stimulus features to changes in perceived emotion. This geometry lives both in modality‑specific sensory cortices (putting music and movement in common metric space) and, in some participants, in posterior superior temporal cortex as a supramodal node. Mechanistically, sensory areas code both elemental features and feature conjunctions that are informative about emotion; together these representations may enable rapid, "direct" perception of social signals and reduce reliance on slow inferential processing.

### Computational‑Social‑Cognitive‑Scientist Hat
- **Kurt Lewin**: He'd view this as formalizing how the person/environment relationship is encoded — representations (R) transform environmental dynamics into behavior‑relevant coordinates (B = f(P,E,R)).
- **David Marr**: Satisfied — the paper maps the *computational* goal (recover emotion across senses), proposes an *algorithmic* geometry (RDMs, feature-conjunctions), and localizes *implementational* substrates (lingual gyrus, STG/pSTG).
- **Egon Brunswik**: Would appreciate the ecological‑validity emphasis — using naturalistic, probabilistic feature mixtures and exploiting environmental covariation (conjunctive cues) to support perception.

### Teaching Hooks
- Play a matched music clip and show the ball animation for a prototypical emotion and ask students to rate emotion; then reveal the RSA result that sensory cortex represents them in similar metric space.
- Analogy: representational geometry is like a city map where distances (not raw coordinates) tell you how similar neighborhoods (stimuli) feel.

### Pedagogical Lens
- Conceptual difficulty: **3/5** (RSA and noise‑ceiling ideas require careful explanation).
- Prerequisites: multivariate neural patterns, correlation distance, basics of RSA, and notions of crossmodal processing.
- Common misconceptions: (1) “Supramodal” means only association cortex — here sensory cortices also share geometry; (2) direct perception implies no higher‑level inference — the paper argues for coexistence of both.
- Discussion prompt: How would you design a cross‑cultural test to separate iconic (shared) feature mappings from culturally learned conventions?

### Connections
Links to Sievers et al. (2013, 2019) on crossmodal structure, work on pSTS/pSTG in action and emotion understanding, and to predictive processing accounts where priors tune sensory representations.

---
