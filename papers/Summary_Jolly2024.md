### Full Citation
Jolly, E. & Chang, L. (2024). The Flatland Fallacy: Over‑reliance on low‑dimensional explanations in social cognition. *(Preprint / Conference paper — see uploaded PDF).*

### Topic Tags
Flatland Fallacy, mentalizing, representation, naturalistic behavior, predictive models

### Core Question / Problem
Why do many models in social cognition over‑simplify complex social phenomena (the "Flatland Fallacy") and what are the consequences for theory and experiment? The paper diagnoses the problem and proposes remedies centered on richer representations and naturalistic tasks.

### Conceptual or Computational Framework
The authors argue from a computational‑representational standpoint: social cognition requires multi‑dimensional, structured representations (causal, compositional, temporal) and algorithms that operate within realistic task worlds. Marr’s levels appear as a guiding frame: computational aim (predict others), algorithmic representation (compositional generative models / transition structure), and implementational plausibility (neural dynamics that can approximate required inference).

### Methods Overview
The paper mixes argument, illustrative simulations, and re-analyses of existing datasets. Core methodological recommendations include moving to naturalistic stimuli, analyzing transition structure in behavior streams, and evaluating models on their ability to generalize across contexts.

### Key Findings
- Low‑dimensional summaries (e.g., single scalar biases) often miss structural constraints that explain why behaviors generalize.
- Transition structure — knowledge about how states evolve — is a powerful, testable signal for prediction in social contexts.
- Rich generative models (hierarchical, compositional) better capture one‑shot learning and inference about others’ goals.
- Empirical tests require time‑continuous tasks, richer annotations, and model‑based behavioral signatures rather than simple aggregate statistics.

### Interpretation & Significance
The Flatland Fallacy critique pushes the field to (1) adopt richer representational hypotheses, (2) design tasks that reveal structural inferences (not just point estimates), and (3) adopt cross‑disciplinary standards (shared tasks, datasets, model tests) akin to Kriegeskorte et al.’s recommendations for cognitive computational neuroscience.

### Computational‑Social‑Cognitive‑Scientist Hat
- Lewin: would endorse emphasis on person × environment (task worlds) interactions.
- Marr: would require explicit separation of levels and formal definitions of representations.
- Brunswik: would welcome the call for ecological sampling and attention to probabilistic cues.

### Teaching Hooks
- Recreate a tiny “Flatland” example: simulate two agents with different internal state spaces and show how a low‑dimensional reading collapses crucial differences.
- Classroom exercise: ask students to design a one‑shot inference task where only a compositional generative model succeeds.

### Pedagogical Lens
- Difficulty: 4/5
- Prereqs: Bayesian inference, basic RL, simple generative models.
- Misconceptions: “more dimensions = overfitting” — clarify role of inductive bias and structured representations.

### Connections
- Ties to Predictive Mind, Generative Models, Transition Structure, and representational analyses.

### Key Quotes or Phrases
- “Reducing social cognition to a few axes risks throwing away the very structure that enables prediction.”  
- “Naturalistic tasks reveal the transition structure that low‑dimensional summaries obscure.”

### Concept Graph
- Rich representations → better generalization because they capture causal & compositional structure.
- Transition structure → predictive accuracy → behavioral adaptation.

### Relevant Terms
- **Existing Terms Used:** Flatland Fallacy, generative model, transition structure, mentalizing, predictive mind.

(end of summary)