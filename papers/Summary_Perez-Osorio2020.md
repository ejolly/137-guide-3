### Full Citation
Perez-Osorio, J. & Wykowska, A. (2020). Adopting the Intentional Stance Toward Natural and Artificial Agents. *Philosophical Psychology* (accepted manuscript Feb 2019).

### Topic Tags
intentional stance, human-robot interaction, social attunement, stance-taking

### Core Question / Problem
When and why do humans adopt the intentional stance — treating a system as if it has beliefs and desires — and what does it imply for interactions with artificial agents (robots, AI)?

### Conceptual or Computational Framework
The paper treats the intentional stance as an efficient predictive strategy: when the design or behavior of an agent makes intentional inference pay off, humans adopt it. Marr’s computational level: achieve accurate prediction in social settings; algorithmic: stance selection (physical/design/intentional) based on cue reliability, task demands, and cultural norms; implementational implications for robot design (appearance, contingency) to promote social attunement.

### Methods Overview
A literature review integrating philosophy (Dennett), developmental findings on stance emergence, cross-cultural variability, and HRI studies showing how robot appearance and contingency modulate adoption of the intentional stance.

### Key Findings
- Intentional stance is a fast, pragmatic strategy rather than a metaphysical claim about true intentionality.
- Robot features that increase contingency, goal-directed motion, and communicative signals increase adoption of the stance and social attunement.
- Cultural norms influence how readily people anthropomorphize and the norms governing acceptable stance adoption.

### Interpretation & Significance
For computational social cognition, the paper clarifies that adopting an intentional stance is an inference policy: agents (including designers) can manipulate cues to make mentalistic predictions more reliable, shaping social interaction. It connects philosophical theory (Dennett) directly to empirical HRI evidence.

### Teaching Hooks
- Show short clips of robots with varying human-likeness; ask students which stance they'd use and why.
- Mini design challenge: propose 3 features that would increase intentional stance adoption for a service robot.

### Pedagogical Lens
- Difficulty: 3/5
- Pre-reqs: intentional stance, agency, predictive models
- Misconception: adopting stance = believing the machine is conscious.

### Connections
- Links to Epley & Waytz, Gray et al., and course glossary entries on the intentional stance and animacy.

### Key Quotes or Phrases
- "Adopting the intentional stance is a pragmatic predictive strategy that facilitates social attunement."

### Concept Graph
- Robot cues (contingency, appearance) → (increase) Intentional stance adoption → (increase) Social attunement/perceived mind.

### Relevant Terms
**Existing Terms Used:** intentional stance; animacy; agency; mentalizing; predictive mind.  

(end of summary)