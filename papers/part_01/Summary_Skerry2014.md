## 2014 — Skerry, A. E., & Saxe, R. (2014). A Common Neural Code for Perceived and Inferred Emotion. *Journal of Neuroscience.*

**Full Citation:** Skerry, A. E., & Saxe, R. (2014). A Common Neural Code for Perceived and Inferred Emotion. *Journal of Neuroscience*, 34(48), 15997–16008.

**Topic Tags:** Emotion perception, MPFC, Representational similarity, Mentalizing

### Core Question / Problem
Do perceived emotions (from faces) and inferred emotions (from contextual descriptions) share neural representations? Skerry & Saxe test whether MPFC/DMPFC contain modality‑independent codes for emotional valence and show that some regions generalize across perceptual and inferential routes.

### Conceptual or Computational Framework
Using a generative/inference perspective, the paper asks whether abstract emotion categories are represented independently of the input modality — implying higher‑level representations that support cross‑modal inference.

### Methods Overview
Multivoxel pattern analyses (MVPA) on fMRI data: participants viewed faces showing emotions and read situational descriptions; classifiers trained on one modality were tested on the other to probe shared codes. ROI and whole‑brain searchlight analyses identify regions with cross‑modal generalization.

### Key Findings
- MMPFC/DMPFC contain patterns that generalize across faces and situation descriptions for valence; other regions (OFC/VMPFC) did not show this cross‑modal code.
- Evidence indicates a shared neural code for attributed emotion in MPFC, supporting an abstract representational level for emotions beyond sensory specifics.
- Results suggest separable roles: sensory regions encode modality‑specific features; MPFC encodes abstracted affective dimensions.

### Interpretation & Significance
The study supports a representational hierarchy: perceptual input is mapped to abstract affective representations that can be accessed both when perceiving emotion and when inferring it from context. This bridges perception and inference — a core problem in social cognition.

### Computational‑Social‑Cognitive‑Scientist Hat
- Computational goal: infer affective valence regardless of input modality.
- Algorithmic strategy: map modality‑specific features into a shared representational space (dimensional valence/arousal).
- Implementation: MPFC/DMPFC as hubs for modality‑independent emotion codes; sensory cortices handle low‑level features.

### Teaching Hooks
- Demonstrate cross‑modal MVPA logic — train on faces, test on stories.
- Use bar charts from the paper (classification accuracy) to show generalization as evidence for shared codes.

### Connections
Links to Mitchell (2009) on representational abstraction and to clinical questions (how impairments in MPFC might disrupt social emotion inference).

### Concept Graph
- Perceptual emotion (faces) + Inferred emotion (situations) → common MPFC representation.
  - **MMPFC/DMPFC:** Abstract affective valence code. **Notable Figures:** Skerry, Saxe. **Related Concepts:** Representation; MVPA; Valence.

### Relevant Terms
- **Existing Terms Used:** MPFC, Representation, Mentalizing, Valence, MVPA.