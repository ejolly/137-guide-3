# Part 1 - Week 3 Lecture Notes

## Mon-10‑13 ToM III Simulation
**Big Questions.** How do we use **our own mind and body** to model others? Where do we hit **limits** in **recursive reasoning**? How do people **coordinate** in time?

### Key Ideas
- **Causal Inference → Recursive Reasoning**
- **Recursive/iterated reasoning:** *We think, they think, we think…* 
  - Most humans can’t go **deeper than ~4–5 levels**.
  - “*2/3 of the average* game” (beauty‑contest) game illustrated **k‑level** distributions
  - **Nash equilibrium** (0) is rarely chosen
  - We're **imperfect information processors**; we have **bounded rationality** 
- **Strategy III: Simulation**: using **your own thoughts/feelings/actions** to infer others’ internal states ("*how would I feel? what would I do?*); two types
   1) **Mirroring (Embodied Simulation):** Automatic vicarious **motor & affective** activations when observing others’ actions/states. Useful for **online, cue‑rich** contexts.
   2) **Self‑Projection (Internal Simulation):** **Autobiographical/episodic** construction of imagined perspectives; we can mentally travel to **past/future/counterfactual** situations and **step into someone’s shoes**. Linked to **default network** functions (memory, imagination, navigation).
- Simulation supports **mutual adaptation**
   - **Synchrony** (coupling in time & state; e.g., tapping, mimicry)
   - **Anticipatory coordination** (coupling across distinct times; e.g., dancing), 
   - **Complementarity** (different internal states; e.g., conversation, teamwork). 
   - **We simulate to predict and adapt.**

### Lecture Notes

- **Recap (Causal inference & development)**
  - **Intuitive physics** and **VOE** reviewed: occlusion/cart experiments (Baillargeon et al.) show infants as young as ~3.5 months **expect** object permanence and look longer at **impossible** events; **belief/expectation** signals without language.
  - **Causal inference facilitates decoupling**: understanding cause→effect supports **pretense** (Leslie, 1987) — the capacity to **represent the world differently from what it is** (“pretending”) → cognitive **decoupling** from immediate perception. This, in turn, scaffolds **representing others’ beliefs** (e.g., false‑belief).
  - **Formal slide definition**: Causal inference = **reasoning backwards** from observations to hidden causes to **predict** future behavior; provides the basis for **higher‑order** ToM.
- **Recursive reasoning (orders of intentionality) — class contest results**
  - Results from the **2/3 of the average** game:
    - **Class average** = **46.4** → **2/3** (rounded) = **31**; **four winners** named on slide. Distribution mapped onto intentionality levels:  
      - **k=0** (first‑order beliefs) ~25–30%  
      - **k=1** (second‑order) ~9%  
      - **k=2** (third‑order) ~7%  
      - **k=3** (fourth‑order) ~3%  
    - Take‑home: humans show **bounded rationality** and **finite recursion** (practically ≤ 4–5 levels), consistent with **Cognitive Hierarchy** models (Nagel; Camerer et al.).
- **ToM Strategy III: Simulation** (two mechanisms emphasized)
  - **Mirroring / Embodied simulation**  
    - Observing actions/emotions **automatically activates** **motor** and **affective** representations (partial resonance) that guide **fast inferences** about another’s state. (Waytz & Mitchell framing on slides.)
  - **Projection / Internal simulation**  
    - We **use autobiographical memory** and **imagination** to construct others’ perspectives—mentally **travel** to **future/past**, to **counterfactuals**, or into **someone else’s shoes**. The same neural system that supports **remembering** and **navigation** supports **simulating** other minds (Buckner & Carroll figure on slides).
- **Mutual adaptation via simulation → social connection**
  - **Synchrony** (time & internal‑state coupling; e.g., tapping, mimicry).  
  - **Anticipatory coordination** (coupling **across distinct times**; e.g., dancing).  
  - **Complementarity** (coupling **across distinct internal states**; e.g., conversation, teamwork).  
  - Slogan from slides: **Simulating to predict. Predicting to adapt. Adapting to connect.**
- **Grand recap via Marr’s levels (applied to the whole first unit)**
  - **Computational (what/why)**: **Detect other minds** to know **how to act** in a social world.
  - **Algorithmic (how/what’s represented)**: **Look for animacy**; **attribute mental states** using **implicit knowledge**, **causal reasoning**, and **simulation**; **minds as action↔mental‑state transitions** (predictive organization).
  - **Implementational (constraints)**: **Cross‑modal animacy cues**; **common system** for remembering/imagining/navigating/simulating; **bounded rationality** (finite recursion).