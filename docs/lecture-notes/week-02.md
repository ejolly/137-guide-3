# Part 1 - Week 2 Lecture Notes

## Wed-10‑08 Animacy II - Implicit Theory-of-mind
**Big Questions.** Beyond biological motion, **what other cues** trigger animacy? How do cross‑modal mappings support **shared social structure**? What happens when the life‑detector **misfires**? How do we **define ToM** formally?

### Key Ideas
- **Three evidence streams for animacy:**  
  **(a) Biological motion**, **(b) Rationality/Efficiency** (goal‑directed, shortest‑path, purposive movement), **(c) Contingency/Interaction** (interdependence among objects; e.g., **chasing**).
- **Cross‑modal mappings:** Kiki–Bouba (shape–sound mapping) shows **consistent cross‑modal correspondences**; modern versions extend to emotion & motion in **music and animation**; the brain extracts a **common dynamic** structure.
- **A third perceptual pathway for social perception:** Beyond classic **what/where**, a system specialized for **“Is it animate?”** and social cues (pSTS/STS‑adjacent systems; conceptually framed in class).
- **When animacy goes wrong:** **Uncanny Valley** = negative affect to near‑human but imperfect agents; framed as **life‑detector conflict**.
- **When mentalizing goes wrong:** **Dehumanization** = **denying mental states** to agents who deserve them. Two forms covered: **Animalistic (denial of uniquely human traits)** and **Mechanistic (denial of human nature)**.
- **Theory‑of‑Mind (ToM) – Premack & Woodruff (1978):** To have a ToM is to **impute mental states** to self and others; it’s a **theory** because states are **unobservable** and the system is used to **predict behavior**.
- Sets up **ToM strategies**: **Implicit Theories**, **Causal Inference**, **Simulation** (Lectures 5–6).

### Lecture Notes

- **Recap: Mentalizing & Animacy (tying the schema to perception)**
  - Re‑emphasis: everything **below the line** (slides) is **perceptual evidence**; everything **above** is **invisible**; **animacy** is the internal, **computed** signal we use to bridge the two.
  - **Three evidence classes** (biological motion, rational/efficient goal‑directedness, contingency) are *not* mutually exclusive and often **co‑occur**, but can be **isolated experimentally** (e.g., self‑propulsion without contact, chasing displays).
- **When animacy goes “wrong”: The **Uncanny Valley** (amplified by motion)**
  - As a stimulus becomes **almost human** (face/body/voice), small mismatches in the **social signal** (shape, timing, contingency) evoke a **negative affective dip**; **motion exacerbates** the effect. The class connected this to current interactions with chatbots: something feels **missing**.
- **When mentalizing goes “wrong”: **Dehumanization** (Haslam)**
  - **Denying deserved mental states** along two **denial axes**:
    - **Animalistic** dehumanization: stripping what separates humans from other animals (typical hits to **rationality**, **self‑control**, etc.).
    - **Mechanistic** dehumanization: stripping **experience/agency**, treating others as **objects/machines**.
  - Mapped back to earlier **Agency/Experience** dimensions; discussion emphasized that while mentalizing is automatic, stories can be **updated** (we can **intervene** on our attributions).
- **Transition: From “Does it have a mind?” to “What state is that mind in?” → **Theory of Mind (ToM)**
  - **Definition used in class** (Premack & Woodruff framing): **capacity to represent another agent’s beliefs, desires, intentions** to **explain** and **predict** behavior; i.e., *how we generate explanations for the mental states we attribute.*
  - **Non‑human primates & infants (preview via video)**: **gaze‑based false‑belief** logic (observer looks where an agent *wrongly believes* an object to be). **Apes** (and later **preverbal infants**) show looking patterns consistent with **attributing false beliefs**, hinting ToM is **not human‑exclusive** and **pre‑verbal** reasoning is measurable with **VOE** (Violation‑of‑Expectation) methods.
- **Three broad ToM “algorithms” (introduced)**
  - **Implicit Theories** (fast rules/schemas we carry).
  - **Causal Inference** (reason backward from observation to hidden causes).
  - **Simulation** (use one’s own mind/body to model another).

---

## Fri-10‑10 ToM II Causal Inference
**Big Questions.** What **algorithms/strategies** do we actually use to infer minds? When do our fast rules **mislead** us? How is social knowledge **organized for prediction**? What **developmental** capacities scaffold ToM?

### Key Ideas

- **Strategy I: Implicit Theories** (fast rules & schemas)
   - **Heider (Naive Psychology):** People act like scientists, generating **explanations** that distinguish **reasons (internal)** from **causes (situations)**.
   - **Jones & Davis (Correspondent Inference):** We attribute intentionality when behavior appears **freely chosen** and **goal‑directed**.
   - **Kelley (Covariation Model):** We weigh **Consistency** (across contexts), **Distinctiveness** (across targets), and **Consensus** (across observers) to infer causes (e.g., why did **Eshin laugh** at a Kevin Hart show?).
   - **Fundamental Attribution Error (FAE):** Tendency to **overestimate personal/dispositional** causes and **underestimate situational** ones when explaining others’ behavior. (Covered with class scenarios & brain‑imaging tie‑in.)
   - **Predictive Implicit Knowledge** (transition structure): **we’re good at predicting transitions** between **mental states** and **actions**; social knowledge is **organized for prediction**. (Tamir et al., 2021; Tamir & Thornton, 2023, presented in lecture.)
   - **Mental‑state space (3 axes):** **Valence**, **Social Impact**, **Rationality**; **Action space (ACT‑FAST)** (e.g., **Abstractness, Creation, Tradition, Food, Animacy, Spiritualism**). **People predict “what comes next”** by moving through these learned geometries.
- **Strategy II: Causal Inference** (developmental/evolutionary building blocks)
   - **Core systems → concepts:** Before language, infants show **intuitive physics** and **object knowledge** (e.g., **object permanence**).
   - **Violation‑of‑Expectation (VOE) paradigm:** If infants/agents look **longer** at **impossible** events, it reveals **expectations** → **proto‑beliefs**.
   - **Pretense & Decoupling (Leslie, 1987):** Ability to **represent the world differently** from what is perceived—foundational for **perspective‑taking** and later **false‑belief** understanding.
- Bridges to **Lecture 6** (Simulation),

### Lecture Notes

- **Implicit Theories of Mind (historical thread and the fast‑and‑frugal strategy)**
  - **Heider’s “Naive Psychology”**: people act like scientists separating **reasons** (internal motives) from **causes** (situations).
  - **Jones & Davis (Correspondent Inference)**: we infer intentions especially when behavior seems **freely chosen** (could they have done otherwise?). Free action cues → stronger mentalizing about **what they were trying to achieve**.
  - **Kelley (Covariation Model)**:
    - We implicitly track **Consistency** (across contexts), **Distinctiveness** (across targets), **Consensus** (across actors).  
    - Example used repeatedly: “Why did **Eshin laugh** at the **Kevin Hart** show?”  
      - If he laughs in general (**consistency**), only at Kevin Hart (**distinctiveness**), and others laugh too (**consensus**), we infer **he likes Kevin Hart**.
  - **Fundamental Attribution Error (FAE)** (defined & reframed):
    - The **tendency** to **overestimate personal** causes and **underestimate situational** ones when explaining others’ behavior.
    - Reframing from lecture: not merely an “error” — could be a **by‑product** of our **spontaneous tendency to see minds**. **Neuroimaging** shows stronger engagement of the same **mentalizing‑related regions** in participants who favored dispositional explanations for ambiguous vignettes (the same stories you answered in class). **We can still update** with more evidence.
- **Our social knowledge is organized for **prediction** (bridging to modern view)**
  - Daily life has **temporal structure** (e.g., **American Time Use**–style transitions: sleep → work → run…). We carry **intuitions** about **what comes next**, both for **actions** and **feelings**.
  - **Key proposal from recent work (presented in slides)**:
    - **Mental‑state space (3 axes)**: **Valence** (±), **Social Impact** (interpersonal force), **Rationality** (uniquely human/reflective).  
    - **Action space (ACT‑FAST taxonomy; 6 axes)**: **Abstractness**, **Creation**, **Tradition**, **Food**, **Animacy**, **Spiritualism**.
    - **Minds as sequences**: Brains can represent a person as the **sequence of mental states we predict they’ll experience next**; this is **useful** precisely because it helps us **anticipate** behavior.
- **(Transition) Core Systems → Causal Inference**
  - Lecture emphasizes that much **pre‑linguistic** understanding comes from **core knowledge** — notably **intuitive physics**. **Violation‑of‑Expectation (VOE)** paradigms show infants stare longer at **impossible** events (e.g., occlusion violations), evidencing **expectations** ⇒ **proto‑beliefs** about the world.
  - **Causal inference (formalized next):** the **general ability to reason backwards** from observations to causes (“Why am I seeing this?” “What did I expect to see?”).
- **In‑class game (announced at end of 10‑10 slides)**
  - “**2/3 of the average**” guessing contest (rules posted): submit one number; aim for 2/3 of class average; no talk/calculators; candy prize next time. (Results revealed in 10‑13.)