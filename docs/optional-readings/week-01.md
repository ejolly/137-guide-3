# Optional Readings — Week 1

---

## n.d. — Pennington, D. (n.d.). History of Social Cognition. *Social Cognition Textbook.*

**Full Citation:** Pennington, D. (n.d.). History of Social Cognition. *Social Cognition Textbook.*

**Topic Tags:** Field theory, Behaviorism, Cognitivism, Constructivism, Timeline terms

### Core Question / Problem

What historical schools of thought shaped the emergence of social cognition (behaviorism → Gestalt/cognitivism → computational cognitive science), and how do these lineages inform contemporary approaches?

### Conceptual or Computational Framework

Historical synthesis: maps intellectual lineage from empiricism & behaviorism through gestalt (Asch, Heider, Bartlett) to Marr's levels and the predictive mind. Emphasizes how representational commitments (schemas, theories) reintroduced internal structure to explain social behavior.

### Methods Overview

Historical narrative drawing on primary papers and classical experiments (Asch impression formation, Bartlett memory work, Heider's attributions).

### Key Findings / Claims

- Behaviorism sidelined mental explanations; Gestalt and cognitive pioneers reintroduced mental structure and meaning.
- Lewin's field theory (B = f(P, E)) anticipated modern representation‑inclusive models (add R).
- The computational turn formalized representation and algorithmic levels (Marr), enabling modern generative/predictive frameworks.

### Interpretation & Significance

Provides students context: why contemporary social cognition focuses on representations, algorithms, and prediction. It explains conceptual shifts and why certain methods (reaction times, narration, neuroimaging) rose to prominence.

### Computational‑Social‑Cognitive‑Scientist Hat

- Lewin: situates behavior as emergent from person and environment; modern accounts add explicit representation R.
- Marr: historical narrative culminates in Marr's levels as a synthesis tool.
- Brunswik: historical emphasis on cue validity and ecological sampling is a throughline.

### Connections

- Ties to all course modules: attributions, schemas, mentalizing, predictive models.

### Key Quotes or Phrases

- "Understanding the history clarifies why we now ask what representations do, not whether they exist."
- "Lewin's field theory foreshadows the modern inclusion of Representations in behavior functions."

### Concept Graph

- Historical movements → theories of mind (schemas, attribution, computation) → modern predictive frameworks

---

## n.d. — Moskowitz, D. S. (n.d.). We Create Internal Mental Representations of External Reality. *Social Cognition Textbook, Chapter 2.*

**Full Citation:** Moskowitz, D. S. (n.d.). We Create Internal Mental Representations of External Reality. *Social Cognition Textbook, Chapter 2.*

**Topic Tags:** Schemas, Prototypes & Exemplars, Embodied cognition, Mindsets

### Core Question / Problem

How are social knowledge and categories represented (schemas, prototypes, exemplars), and how do these representations shape perception, memory, and behavior?

### Conceptual or Computational Framework

The chapter presents a representational‑processing framework: representations (schemas, exemplars, prototypes, frames, scripts) mediate perception and action. It highlights interactions between bottom‑up associative learning and top‑down schema effects (priors), consistent with predictive processing accounts.

### Methods Overview

Survey of classic experiments (e.g., Bartlett, Markus self‑schema studies, Cohen role schema work) and more modern experimental paradigms (priming, subliminal triggers, IF→THEN relational elicitation).

### Key Findings

- Representations are fuzzy, probabilistic, and can be organized as prototypes or exemplars; which representation is used depends on familiarity and context.
- Self‑schemas facilitate encoding and retrieval for self‑relevant traits (faster RTs, richer recall).
- Embodied cognition: bodily states (temperature, posture, facial muscles) can implicitly influence social judgments (warmth, affect), often outside awareness.
- Ideomotor/priming effects demonstrate that activated representations can trigger matching behaviors (e.g., elderly stereotype priming slows walking); but replication crises temper some strong claims.

### Interpretation & Significance

The chapter stitches together classical schema theory with emerging embodied and automaticity findings. Pedagogically it gives students an operational toolkit to think about how knowledge structures influence perception and action, and how mindsets and construal level moderate processing.

### Computational‑Social‑Cognitive‑Scientist Hat

- Lewin: schemas are part of R in B = f(P,E,R) and shape goal‑directed action.
- Marr: computational goal = compress and infer category membership; algorithmic = exemplar matching vs prototype probability estimation.
- Brunswik: highlights cue validity and IF→THEN relations for relational theories.

### Connections

- Links to Heider's animacy (schemas for agents), Mitchell's Marr framing (representations as algorithmic objects), and later lectures on predictive models.

### Key Quotes or Phrases

- "Schemas serve as filters that make stimuli knowable and actionable."
- "Embodied states often trigger metaphorically linked social inferences outside awareness."

### Concept Graph

- Experience → Associations → Schema (prototype/exemplar) → Perception & Memory biases → Behavior

---

## n.d. — Dennett, D. C. (n.d.). A Précis of The Intentional Stance. *Philosophical Review.*

**Full Citation:** Dennett, D. C. (n.d.). A Précis of The Intentional Stance. *Philosophical Review.*

**Topic Tags:** intentional stance, Searle critique, heuristic overlay, consensus in philosophy of mind

### Core Question / Problem

Why is the intentional stance defensible as a pragmatic, heuristic strategy given critiques (e.g., Searle's Chinese Room) that demand metaphysical grounding?

### Conceptual or Computational Framework

Dennett argues the stance is a "heuristic overlay" that captures a community of practices; disagreements often reflect overstatements rather than deep problems. The defense emphasizes explanatory power and empirical adequacy over metaphysical commitments.

### Methods Overview

Essay‑length précis with commentary on contemporary debates (Sellars, Quine, Searle, Fodor) and notes on the consensus shifting toward a moderate, pragmatic view.

### Key Findings

- Responds to Searle: even if biochemistry produces intentionality, that doesn't resolve the epistemic/practical reasons we adopt the stance.
- Philosophers are converging on seeing intentional attribution as a useful heuristic rather than a metaphysical claim.

### Interpretation & Significance

The Précis helps students situate Dennett historically and shows why the Intentional Stance remains influential: it provides an operational toolkit for prediction and explanation across domains (AI, economics, psychology).

---

## 1971 — Dennett, D. C. (1971). Intentional Systems. *The Journal of Philosophy.*

**Full Citation:** Dennett, D. C. (1971). Intentional Systems. *The Journal of Philosophy.*

**Topic Tags:** intentional stance, design stance, physical stance, intentional systems, rationality, heuristics

### Core Question / Problem

What does it mean to treat systems (organisms, machines) as having beliefs and desires — and how useful is that strategy for explanation and prediction?

### Conceptual or Computational Framework

Dennett defines an Intentional System as any system whose behavior can be predicted by ascribing beliefs, desires, and rationality. He contrasts three explanatory stances: Physical (laws), Design (function), and Intentional (attributing mental states). The intentional stance is a heuristically powerful, stance‑level algorithm for prediction. Map to Marr: computational level = predicting behavior; algorithmic level = adopting a stance (rule set for ascription); implementational level = physical/biological substrate (irrelevant to stance validity).

### Methods Overview

Philosophical analysis and illustration (AI/chess, game theory, Skinner's behaviorism counterexamples). Dennett uses thought experiments and cross‑disciplinary examples (economics, AI) to show how intentional descriptions simplify complex design problems.

### Key Findings

- Intentional characterization is useful even for non‑biological systems (chess programs) and yields genuine predictive power without needing metaphysical claims about consciousness.
- Treating agents as rational approximators explains why economics and game theory succeed even if psychology must explain that rationality.
- The concept is "uncluttered" — it avoids metaphysical commitments and focuses on predictive/organizational utility.

### Interpretation & Significance

Dennett offers a pragmatic account: intentionality as a tool, not a metaphysical property. For social cognition, this legitimizes mental‑state attribution as an adaptive predictive strategy (aligns with course's Intentional Stance entry). It also explains cross‑disciplinary borrowings (AI, economics) where intentional terms function as useful heuristics.

### Computational‑Social‑Cognitive‑Scientist Hat

- Lewin: Intentional ascription is a representational heuristic within the life‑space affecting behavior prediction.
- Marr: Intentional stance sits at an algorithmic/heuristic level for social prediction.

### Connections

- Directly connects to Intentional Stance, Design Stance, Mentalizing, and Generative Models in the glossary.

### Key Quotes or Phrases

- "The concept of an Intentional system is a relatively uncluttered and unmetaphysical notion."

### Concept Graph

- System complexity → choice of stance (physical/design/intentional) → prediction accuracy.

---

## 2010 — Epley, N., & Waytz, A. (2010). Mind Perception. *Handbook of Social Psychology (5th ed.).*

**Full Citation:** Epley, N., & Waytz, A. (2010). Mind Perception. In S. T. Fiske (Ed.), *Handbook of Social Psychology (5th ed.).*

**Topic Tags:** mentalizing, mind perception, animacy, agency, experience

### Core Question / Problem

How do people perceive "minds" in others (human and non‑human), what dimensions organize those perceptions, and how do those perceptions influence social judgment and behavior?

### Conceptual or Computational Framework

Epley & Waytz frame mind perception as a graded, two‑dimensional attributional space (Experience vs Agency) that functions as an early *preattributional* step in social cognition: first, perceivers ask "Does it have a mind?" then "What state is it in?". This sits naturally at Marr's Algorithmic level (representations: 2‑D mind space; operations: cues→attribution) and connects to the Computational level via the goal of enabling prediction and coordination in social environments.

### Methods Overview

This is a conceptual synthesis and review integrating laboratory experiments (e.g., cue manipulations that trigger animacy), developmental studies (infant sensitivity to teleology/goal-directed motion), cross‑cultural evidence, and moral judgment paradigms (e.g., attributions of responsibility and dehumanization). Core manipulations reviewed include motion cues, agency cues, moral contexts, and social distance (ingroup/outgroup).

### Key Findings

- Mind perception is structured primarily along two separable dimensions: **Experience** (capacity to feel) and **Agency** (capacity to plan/act). These vary independently across targets (e.g., pets = high experience/low agency; gods = high agency/low experience).
- Perceivers use perceptual and contextual cues (animacy, goal‑directed motion, social closeness) to infer mind status; these inferences serve predictive and moral functions (assigning blame/praise, granting moral worth).
- Mind perception is modulated by social distance and culture: ingroup members are attributed richer mental capacities than distant outgroups, and interdependent cultures show greater habitual perspective taking.
- Errors and biases occur: people over‑attribute intentionality (leading to blame) and under‑attribute experience to dehumanized groups; activation of mind perception is effortful and context‑dependent.

### Interpretation & Significance

Epley & Waytz show that mind perception is not a binary cognitive act but a graded representational mapping that scaffolds later causal attributions and moral evaluations. Mechanistically, the two‑dimensional representation compresses complex mental states into actionable summaries for social coordination and prediction. In course framing, this work demonstrates how Lewin's B = f(P,E,R) benefits from an explicit representation (R) for other minds and connects to the Predictive Mind: attributing mental states improves prediction and coordination.

### Computational‑Social‑Cognitive‑Scientist Hat

- Lewin: Mind perception supplies the "R" (representation) that mediates how person and environment produce behavior.
- Marr: Algorithmic level — the two‑dimensional mind map is the representation; computational level — goal is accurate social prediction & moral evaluation.
- Brunswik: Emphasizes cue validity and ecological sampling — which cues reliably indicate agency or experience across contexts.

### Connections

Links to animacy, intentional stance, Theory of Mind, predictive processing, and dehumanization literature. Useful precursor reading before Wang et al. (2025).

### Key Quotes or Phrases

- "Mind perception is a pre‑attributional process: first do we see a mind, then what is that mind like?"
- "Perceiving mindful agency is tied to causal responsibility; perceiving experience is tied to moral worth."

### Concept Graph

- Perceptual cues → (animacy detection) → Mind presence estimate → Map onto (Agency, Experience) → Guides prediction & moral judgment.

---

## 2007 — Gray, H. M., Gray, K., & Wegner, D. M. (2007). Dimensions of Mind Perception. *Science.*

**Full Citation:** Gray, H. M., Gray, K., & Wegner, D. M. (2007). Dimensions of Mind Perception. *Science.*

**Topic Tags:** mind perception, agency, experience, dimensionality reduction, social evaluation

### Core Question / Problem

Do people represent minds in others along meaningful dimensions, and if so, what are those dimensions and their psychological consequences?

### Conceptual or Computational Framework

Gray et al. provide experimental evidence for a low-dimensional representation of minds (primarily Agency and Experience). At Marr's levels: computational goal = compress a high-dimensional space of possible mental features into tractable dimensions for fast inference; algorithmic = two-dimensional mapping; implementational = patterns of attribution consistent across participants and correlations with moral judgments.

### Methods Overview

Multiple experiments: participants rated a variety of targets (humans, animals, gods, robots) on trait adjectives; principal components / factor analyses revealed two stable dimensions. Follow-up behavioral measures connect dimensions to moral judgments and perceived responsibility.

### Key Findings

- A two-factor structure (Experience, Agency) captures most variance in mind attributions.
- These dimensions predict distinct moral consequences: Experience predicts moral rights (do not harm), Agency predicts moral responsibility (blame, praise).

### Interpretation & Significance

A compact representational account explains diverse phenomena — anthropomorphism, dehumanization, moral judgments — by showing that a small set of latent dimensions governs social inference. This aligns with computational cognitive science's emphasis on compressed representations for efficient prediction.

### Connections

- Strongly connected to Epley & Waytz, Waytz et al., and course glossary terms like agency/experience and moral typecasting.

### Key Quotes or Phrases

- "Mind perception is organized along dimensions of experience and agency."

### Concept Graph

- Target features → (map to) Agency/Experience → (drive) moral judgments.

---

## 1944 — Heider, F., & Simmel, M. (1944). An Experimental Study of Apparent Behavior. *Journal of Psychology.*

**Full Citation:** Heider, F., & Simmel, M. (1944). An Experimental Study of Apparent Behavior. *Journal of Psychology.*

**Topic Tags:** Attribution theory, Animacy, Intentional stance

### Core Question / Problem

How do simple motion cues (shapes moving on a screen) provoke attributions of intentional action, social motives, and personality — i.e., when do observers treat abstract motion as "agents"?

### Conceptual or Computational Framework

Heider & Simmel operationalize the perceiver as a naïve scientist who infers internal states (beliefs, desires, intentions) from minimal perceptual input. At Marr's levels: computationally, the problem is "infer causes (agents, goals) from motion"; algorithmically, it is mapping kinematic patterns to intentional explanations; implementational details are left unspecified.

### Methods Overview

Participants watched a short silent film showing geometric shapes (triangles, circle, rectangle) moving in a simple 2-D arena. They were asked to describe what they saw in their own words. The key manipulation is purely perceptual: only motion and spatial relations vary.

### Key Findings

- Nearly all observers provided narrativized, agentic descriptions (e.g., "the big triangle chased the little one to punish it"), attributing goals, beliefs, and social roles to geometric shapes.
- Motion patterns (self-propulsion, contingent interaction, approach/avoidance, goal-directed trajectories) reliably trigger attributions of animacy and intentionality.
- Observers spontaneously create causal and moral narratives from minimal cues.

### Interpretation & Significance

Heider & Simmel provide a clear demonstration that perception alone can trigger high-level social inferences. The study shows that agency detection and mentalizing are fast, automatic, and driven by diagnostic motion signatures — a foundational result for research on animacy perception, mentalizing, and the intentional stance.

### Computational‑Social‑Cognitive‑Scientist Hat

- Lewin: B = f(P, E, R) — This shows how perceptual input P (motion) combined with prior Representations (R: schemas about agents) shapes behavior (attribution).
- Marr: Computational goal = infer hidden agents/goals; algorithmic = mapping motion features → intentional explanation; implementational = unspecified.
- Brunswik: Emphasizes ecological validity — motion cues are probabilistic signals of agency and the perceiver uses ecological sampling (available cues) to infer hidden causes.

### Connections

- Links to animacy literature, biological motion (Johansson), and predictive‑processing accounts where small prediction errors about self‑propelled motion trigger agent hypotheses.

### Key Quotes or Phrases

- "Observers impose intentions and social roles on moving shapes."
- "Motion alone is sufficient to elicit richly structured social narratives."

### Concept Graph

- Motion cues (self‑propulsion, contingency) → Animacy detection → Intentional stance → Mentalizing (goal/trait attributions)

---

## 2020 — Perez-Osorio, J., & Wykowska, A. (2020). Adopting the Intentional Stance Toward Natural and Artificial Agents. *Philosophical Psychology.*

**Full Citation:** Perez-Osorio, J., & Wykowska, A. (2020). Adopting the Intentional Stance Toward Natural and Artificial Agents. *Philosophical Psychology.*

**Topic Tags:** intentional stance, human-robot interaction, social attunement, stance-taking

### Core Question / Problem

When and why do humans adopt the intentional stance — treating a system as if it has beliefs and desires — and what does it imply for interactions with artificial agents (robots, AI)?

### Conceptual or Computational Framework

The paper treats the intentional stance as an efficient predictive strategy: when the design or behavior of an agent makes intentional inference pay off, humans adopt it. Marr's computational level: achieve accurate prediction in social settings; algorithmic: stance selection (physical/design/intentional) based on cue reliability, task demands, and cultural norms; implementational implications for robot design (appearance, contingency) to promote social attunement.

### Methods Overview

A literature review integrating philosophy (Dennett), developmental findings on stance emergence, cross-cultural variability, and HRI studies showing how robot appearance and contingency modulate adoption of the intentional stance.

### Key Findings

- Intentional stance is a fast, pragmatic strategy rather than a metaphysical claim about true intentionality.
- Robot features that increase contingency, goal-directed motion, and communicative signals increase adoption of the stance and social attunement.
- Cultural norms influence how readily people anthropomorphize and the norms governing acceptable stance adoption.

### Interpretation & Significance

For computational social cognition, the paper clarifies that adopting an intentional stance is an inference policy: agents (including designers) can manipulate cues to make mentalistic predictions more reliable, shaping social interaction. It connects philosophical theory (Dennett) directly to empirical HRI evidence.

### Connections

- Links to Epley & Waytz, Gray et al., and course glossary entries on the intentional stance and animacy.

### Key Quotes or Phrases

- "Adopting the intentional stance is a pragmatic predictive strategy that facilitates social attunement."

### Concept Graph

- Robot cues (contingency, appearance) → (increase) Intentional stance adoption → (increase) Social attunement/perceived mind.

---
